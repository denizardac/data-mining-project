# -*- coding: utf-8 -*-
"""DataMining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1stXdTET7nznn4jydZDTDMuphk-6pu1Uj
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/gdrive/')
# %cd "/content/gdrive/My Drive/"

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/gdrive/')
file_path = '/content/gdrive/My Drive/CENG464/Data_processed.xlsx'
data = pd.read_excel(file_path)

original_data = data.copy()  # copy original

print(data.head())

# missing values sum
print(data.isnull().sum())

missing_info = pd.DataFrame({
    "Missing Values": data.isnull().sum(),
    "Percentage": (data.isnull().sum() / len(data)) * 100
})

# check the missing values
missing_info = missing_info[missing_info["Missing Values"] > 0].sort_values(by="Missing Values", ascending=False)

print(missing_info)

"""longtitute float olmayan yanlış değer tespiti

"""

for column in data.columns:
    if data[column].dtype == 'object':  # check strings
        print(f"Sütun: {column}")
        print(data[column].unique())  # unique values list

data['Longitude'] = data['Longitude'].astype(str)

data['Longitude'] = data['Longitude'].str.replace(r'85\.1\s*4', '85.14', regex=True)

# to numeric
data['Longitude'] = pd.to_numeric(data['Longitude'], errors='coerce')

# check results
print(data['Longitude'].unique())  # check unique values again

"""double check

"""

print(data['Longitude'].unique())

# check distribution of longtitude
import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(data['Longitude'], kde=True)
plt.title('Longitude Distribution')
plt.show()

"""longtitude missing values replaced by KNN

"""

from sklearn.impute import KNNImputer

imputer = KNNImputer(n_neighbors=5)
data[['Longitude']] = imputer.fit_transform(data[['Longitude']])

# check distribution of herbicide year

import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(data['HerbicideYear'], kde=True)
plt.title('HerbicideYear Distribution')
plt.show()

"""heribideyear missing values filled by Forward hill  method


"""

data['HerbicideYear'] = data['HerbicideYear'].ffill()

# check distribution of herbicide year again for validity

import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(data['HerbicideYear'], kde=True)
plt.title('HerbicideYear Distribution')
plt.show()

from sklearn.impute import KNNImputer

# KNN Imputer usage for herbicide month
imputer = KNNImputer(n_neighbors=5)
data['HerbicideMonth'] = imputer.fit_transform(data[['HerbicideMonth']])

# herbicide day filled by median values

data['HerbicideDay'].fillna(data['HerbicideDay'].median(), inplace=True)

data['HerbicideWeekNum'] = imputer.fit_transform(data[['HerbicideWeekNum']])

# usage of a model to fill the missing values in daysfromsowingtoherbicide
from sklearn.linear_model import LinearRegression

target = 'DaysFromSowingToHerbicide'
features = ['HerbicideYear', 'HerbicideMonth', 'HerbicideDay']

model = LinearRegression()

train_data = data.dropna(subset=features + [target])
X_train = train_data[features]
y_train = train_data[target]

X_test = data.loc[data[target].isnull(), features]

model.fit(X_train, y_train)
data.loc[data[target].isnull(), target] = model.predict(X_test)

target = 'DaysFromHerbicideToHarvest'

train_data = data.dropna(subset=features + [target])
X_train = train_data[features]
y_train = train_data[target]

X_test = data.loc[data[target].isnull(), features]

model.fit(X_train, y_train)
data.loc[data[target].isnull(), target] = model.predict(X_test)

# check missing values again
print(data.isnull().sum())

import matplotlib.pyplot as plt
import seaborn as sns

# DaysFromSowingToHerbicide distr.
plt.figure(figsize=(12, 6))
sns.histplot(data['DaysFromSowingToHerbicide'], bins=20, kde=True)
plt.title("DaysFromSowingToHerbicide Distribution")
plt.xlabel("Days")
plt.ylabel("Frequency")
plt.show()

# DaysFromHerbicideToHarvest distr.
plt.figure(figsize=(12, 6))
sns.histplot(data['DaysFromHerbicideToHarvest'], bins=20, kde=True)
plt.title("DaysFromHerbicideToHarvest Distribution")
plt.xlabel("Days")
plt.ylabel("Frequency")
plt.show()

# check the records
columns_to_check = ['HerbicideYear', 'HerbicideMonth', 'HerbicideWeekNum',
                    'DaysFromSowingToHerbicide', 'DaysFromHerbicideToHarvest', 'HerbicideDay']

# logic check
logical_ranges = {
    'HerbicideYear': (2016, 2022),
    'HerbicideMonth': (1, 12),
    'HerbicideWeekNum': (1, 53),
    'DaysFromSowingToHerbicide': (0, 60),
    'DaysFromHerbicideToHarvest': (30, 180),
    'HerbicideDay': (1, 31)
}

for column in columns_to_check:
    print(f"\nKontrol Edilen Değişken: {column}")

    # any negative values?
    negative_values = (data[column] < 0).sum()
    print(f"Negatif Değer Sayısı: {negative_values}")

    # logical limit check
    min_limit, max_limit = logical_ranges[column]
    below_min = (data[column] < min_limit).sum()
    above_max = (data[column] > max_limit).sum()
    print(f"{min_limit}'den küçük değerler: {below_min}")
    print(f"{max_limit}'den büyük değerler: {above_max}")

    # report
    if negative_values > 0 or below_min > 0 or above_max > 0:
        print(f"⚠️ {column} değişkeninde tutarsız değerler mevcut.")
    else:
        print(f"✅ {column} değişkeni mantıksal sınırlar içerisinde.")

print("\nTüm kontroller tamamlandı.")

invalid_rows = data[data['DaysFromSowingToHerbicide'] < 0]

# negative values?
print("Negatif değer içeren satırlar:")
print(invalid_rows[['DaysFromZerotoSowing', 'DaysFromSowingToHerbicide',
                    'HerbicideYear', 'HerbicideMonth', 'HerbicideDay']])


import matplotlib.pyplot as plt

plt.hist(data['DaysFromSowingToHerbicide'], bins=50)
plt.title('DaysFromSowingToHerbicide Dağılımı')
plt.xlabel('Gün Farkı')
plt.ylabel('Frekans')
plt.show()

# check negative find median
median_value = data['DaysFromSowingToHerbicide'][data['DaysFromSowingToHerbicide'] > 0].median()
print(f"Medyan Değer: {median_value}")

# fill with median
data.loc[data['DaysFromSowingToHerbicide'] < 0, 'DaysFromSowingToHerbicide'] = median_value

# show dist. again
import matplotlib.pyplot as plt

plt.hist(data['DaysFromSowingToHerbicide'], bins=50)
plt.title('Düzeltilmiş DaysFromSowingToHerbicide Dağılımı')
plt.xlabel('Gün Farkı')
plt.ylabel('Frekans')
plt.show()

!pip install catboost

print(data['GrainYield'].unique())

data['GrainYield'] = data['GrainYield'].map({'C': 0, 'B': 1, 'A': 2})

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix,
    matthews_corrcoef, roc_curve, auc
)
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
import warnings
import sys

warnings.filterwarnings("ignore")

# features
feature_columns = data.columns[data.columns.get_loc('Longitude'):data.columns.get_loc('DaysFromHerbicideToHarvest') + 1]
soil_types = ['SoilType_Heavy', 'SoilType_Medium', 'SoilType_Low']

classifiers = {
    'Logistic Regression': LogisticRegression(max_iter=5000),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'XGBoost': XGBClassifier(eval_metric='mlogloss', use_label_encoder=False),
    'Extra Trees': ExtraTreesClassifier(),
    'Support Vector Machine': SVC(probability=True),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'Decision Tree': DecisionTreeClassifier(),
    'AdaBoost': AdaBoostClassifier(algorithm='SAMME'),
}

results_soil = []
conf_matrix = None
best_classifier_name = None
best_auc = 0
best_cm = None
roc_data = {}

for soil_type in soil_types:
    subset = data[data[soil_type] == 1]
    X = subset[feature_columns]
    y = subset['GrainYield']

    if y.isnull().any():
        continue

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    for clf_name, clf in classifiers.items():
        fold_accuracies = []
        fold_aucs = []
        fold_mccs = []
        fold_f1s = []
        fold_precisions = []
        fold_recalls = []
        roc_curves = []

        for train_idx, test_idx in skf.split(X_scaled, y):
            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            clf.fit(X_train, y_train)
            y_pred = clf.predict(X_test)
            y_proba = clf.predict_proba(X_test) if hasattr(clf, "predict_proba") else None

            acc = accuracy_score(y_test, y_pred)
            mcc = matthews_corrcoef(y_test, y_pred)
            f1 = f1_score(y_test, y_pred, average='weighted')
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')

            if y_proba is not None and y_proba.shape[1] == len(np.unique(y)):
                try:
                    auc_score = roc_auc_score(y_test, y_proba, multi_class='ovo')
                    classes = np.unique(y)
                    if len(classes) == 2:
                        positive_class = classes[1]
                        fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=positive_class)
                        roc_curves.append((fpr, tpr))
                    else:
                        positive_class = classes[-1]
                        fpr, tpr, _ = roc_curve(y_test, y_proba[:, -1], pos_label=positive_class)
                        roc_curves.append((fpr, tpr))
                except ValueError:
                    auc_score = np.nan
            else:
                auc_score = np.nan

            fold_accuracies.append(acc)
            fold_aucs.append(auc_score)
            fold_mccs.append(mcc)
            fold_f1s.append(f1)
            fold_precisions.append(precision)
            fold_recalls.append(recall)

        avg_accuracy = np.mean(fold_accuracies)
        avg_auc = np.nanmean(fold_aucs)
        avg_mcc = np.mean(fold_mccs)
        avg_f1 = np.mean(fold_f1s)
        avg_precision = np.mean(fold_precisions)
        avg_recall = np.mean(fold_recalls)

        # update best auc
        if avg_auc > best_auc:
            best_auc = avg_auc
            best_classifier_name = clf_name
            # Son fold'un y_test, y_pred'ini kaydetmek için y_test, y_pred'i dışarı çıkarıyoruz
            # Yukarıdaki döngüden çıktığımızda son fold'un y_test, y_pred'i bu değişkende kaldı.
            best_cm = confusion_matrix(y_test, y_pred)

        # Sonuçları kaydet
        results_soil.append({
            'Category': soil_type,
            'Classifier': clf_name,
            'Accuracy': avg_accuracy,
            'AUC': avg_auc,
            'MCC': avg_mcc,
            'F1': avg_f1,
            'Precision': avg_precision,
            'Recall': avg_recall
        })

        # save roc
        # Tüm foldlardan bir ROC eğrisi var. Burada ilk ROC eğrisini temsil olarak alabiliriz.
        # Ortalama ROC için ekstra işlem gerekir. Burada sadece ilk fold ROC'unu gösteriyoruz.
        if roc_curves:
            roc_data[(soil_type, clf_name)] = roc_curves[0]  # ilk ROC eğrisi

results_soil_df = pd.DataFrame(results_soil)
display(results_soil_df)

# confusion matrix for best classifier
if best_cm is not None:
    plt.figure(figsize=(8, 6), dpi=120)
    sns.heatmap(best_cm, annot=True, fmt='d', cmap='coolwarm', cbar=True, linewidths=1.5)
    plt.title(f'Confusion Matrix - Best Classifier: {best_classifier_name}', fontsize=14)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.tight_layout()
    plt.show()

# ROC eğrilerini çizelim (her sınıflandırıcı için genel bir ROC eğrisi)
plt.figure(figsize=(10, 8), dpi=120)
colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'lime']

# Her sınıflandırıcı için bir ROC eğrisi çizmek
aggregated_roc_data = {}
for (cat, clf_name), (fpr, tpr) in roc_data.items():
    if clf_name not in aggregated_roc_data:
        aggregated_roc_data[clf_name] = {'fpr': [], 'tpr': []}
    aggregated_roc_data[clf_name]['fpr'].append(fpr)
    aggregated_roc_data[clf_name]['tpr'].append(tpr)

for idx, (clf_name, values) in enumerate(aggregated_roc_data.items()):
    # FPR ve TPR'nin ortalamasını alarak genel bir ROC eğrisi oluştur
    mean_fpr = np.linspace(0, 1, 100)
    mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(values['fpr'], values['tpr'])], axis=0)
    mean_tpr[-1] = 1.0
    roc_auc = auc(mean_fpr, mean_tpr)
    plt.plot(mean_fpr, mean_tpr, color=colors[idx % len(colors)], lw=2, label=f'{clf_name} (AUC = {roc_auc:.3f})')

# random guess
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1.5, label='Random Guess')

plt.title('ROC Curves for Classifiers (Aggregated)', fontsize=14)
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.legend(loc='lower right', fontsize=10)
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import (
    roc_auc_score, accuracy_score, f1_score, precision_score, recall_score,
    matthews_corrcoef, confusion_matrix, roc_curve, auc
)
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
import warnings
import sys

warnings.filterwarnings("ignore")

# features
feature_columns = data.columns[data.columns.get_loc('Longitude'):data.columns.get_loc('DaysFromHerbicideToHarvest') + 1]
sowing_schedules = ['SowingSchedule_T1', 'SowingSchedule_T2', 'SowingSchedule_T3', 'SowingSchedule_T4']

classifiers = {
    'Logistic Regression': LogisticRegression(max_iter=5000),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'XGBoost': XGBClassifier(eval_metric='mlogloss', use_label_encoder=False),
    'Extra Trees': ExtraTreesClassifier(),
    'Support Vector Machine': SVC(probability=True),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'Decision Tree': DecisionTreeClassifier(),
    'AdaBoost': AdaBoostClassifier(algorithm='SAMME'),
}

results_sowing = []
conf_matrix = None
best_classifier_name = None
best_auc = 0
best_cm = None
roc_data = {}

for sowing_schedule in sowing_schedules:
    subset = data[data[sowing_schedule] == 1]
    X = subset[feature_columns]
    y = subset['GrainYield']

    if y.isnull().any():
        continue

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    for clf_name, clf in classifiers.items():
        fold_accuracies = []
        fold_aucs = []
        fold_mccs = []
        fold_f1s = []
        fold_precisions = []
        fold_recalls = []
        roc_curves = []

        for train_idx, test_idx in skf.split(X_scaled, y):
            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            clf.fit(X_train, y_train)
            y_pred = clf.predict(X_test)
            y_proba = clf.predict_proba(X_test) if hasattr(clf, "predict_proba") else None

            acc = accuracy_score(y_test, y_pred)
            mcc = matthews_corrcoef(y_test, y_pred)
            f1 = f1_score(y_test, y_pred, average='weighted')
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')

            if y_proba is not None and y_proba.shape[1] == len(np.unique(y)):
                try:
                    auc_score = roc_auc_score(y_test, y_proba, multi_class='ovo')
                    classes = np.unique(y)
                    if len(classes) == 2:
                        positive_class = classes[1]
                        fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=positive_class)
                    else:
                        positive_class = classes[-1]
                        fpr, tpr, _ = roc_curve(y_test, y_proba[:, -1], pos_label=positive_class)
                    roc_curves.append((fpr, tpr))
                except ValueError:
                    auc_score = np.nan
            else:
                auc_score = np.nan

            fold_accuracies.append(acc)
            fold_aucs.append(auc_score)
            fold_mccs.append(mcc)
            fold_f1s.append(f1)
            fold_precisions.append(precision)
            fold_recalls.append(recall)

        avg_accuracy = np.mean(fold_accuracies)
        avg_auc = np.nanmean(fold_aucs)
        avg_mcc = np.mean(fold_mccs)
        avg_f1 = np.mean(fold_f1s)
        avg_precision = np.mean(fold_precisions)
        avg_recall = np.mean(fold_recalls)

        # En iyi AUC'yi güncelle
        if avg_auc > best_auc:
            best_auc = avg_auc
            best_classifier_name = clf_name
            best_cm = confusion_matrix(y_test, y_pred)  # son foldun y_test, y_pred verisi

        # Sonuçları kaydet
        results_sowing.append({
            'Category': sowing_schedule,
            'Classifier': clf_name,
            'Accuracy': avg_accuracy,
            'AUC': avg_auc,
            'MCC': avg_mcc,
            'F1': avg_f1,
            'Precision': avg_precision,
            'Recall': avg_recall,
        })

        # ROC verilerini kaydet (ilk foldun ROC eğrisini baz alıyoruz)
        if roc_curves:
            roc_data[(sowing_schedule, clf_name)] = roc_curves[0]

results_sowing_df = pd.DataFrame(results_sowing)
display(results_sowing_df)

# En iyi sınıflandırıcı için Confusion Matrix
if best_cm is not None:
    plt.figure(figsize=(8, 6), dpi=120)
    sns.heatmap(best_cm, annot=True, fmt='d', cmap='coolwarm', cbar=True, linewidths=1.5)
    plt.title(f'Confusion Matrix - Best Classifier: {best_classifier_name}', fontsize=14)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.tight_layout()
    plt.show()

# ROC eğrilerini çizelim (her sınıflandırıcı için genel bir ROC eğrisi)
plt.figure(figsize=(10, 8), dpi=120)
colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'lime']

# Her sınıflandırıcı için bir ROC eğrisi çizmek
aggregated_roc_data = {}
for (cat, clf_name), (fpr, tpr) in roc_data.items():
    if clf_name not in aggregated_roc_data:
        aggregated_roc_data[clf_name] = {'fpr': [], 'tpr': []}
    aggregated_roc_data[clf_name]['fpr'].append(fpr)
    aggregated_roc_data[clf_name]['tpr'].append(tpr)

for idx, (clf_name, values) in enumerate(aggregated_roc_data.items()):
    mean_fpr = np.linspace(0, 1, 100)
    mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(values['fpr'], values['tpr'])], axis=0)
    mean_tpr[-1] = 1.0
    roc_auc = auc(mean_fpr, mean_tpr)
    plt.plot(mean_fpr, mean_tpr, color=colors[idx % len(colors)], lw=2, label=f'{clf_name} (AUC = {roc_auc:.3f})')

# Rastgele tahmin çizgisi
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1.5, label='Random Guess')

plt.title('ROC Curves for Classifiers (Aggregated)', fontsize=14)
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.legend(loc='lower right', fontsize=10)
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

results_df = pd.concat([results_soil_df, results_sowing_df], ignore_index=True)

"""**time for feature selection**

"""

from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier  # rfe

feature_columns = data.columns[data.columns.get_loc('Longitude'):data.columns.get_loc('DaysFromHerbicideToHarvest') + 1]

selected_features = {}  # every feature selected
# SoilType with RFE
for soil_type in ['SoilType_Heavy', 'SoilType_Medium', 'SoilType_Low']:
    subset = data[data[soil_type] == 1]
    X = subset[feature_columns]
    y = subset['GrainYield']

    model = RandomForestClassifier()  # rfe
    rfe = RFE(model, n_features_to_select=10)
    rfe.fit(X, y)

    selected_features[soil_type] = list(X.columns[rfe.support_])
    print(f"{soil_type} için seçilen özellikler: {selected_features[soil_type]}")

# SowingSchedule with RFE
for sowing_schedule in ['SowingSchedule_T1', 'SowingSchedule_T2', 'SowingSchedule_T3', 'SowingSchedule_T4']:
    subset = data[data[sowing_schedule] == 1]
    X = subset[feature_columns]
    y = subset['GrainYield']

    model = RandomForestClassifier()
    rfe = RFE(model, n_features_to_select=10)
    rfe.fit(X, y)

    selected_features[sowing_schedule] = list(X.columns[rfe.support_])
    print(f"{sowing_schedule} için seçilen özellikler: {selected_features[sowing_schedule]}")

"""**after selecting the features** lets start to do feature selection and find results"""

# ROC verilerini toplamak için sözlük
roc_data = {}

# Mevcut kodun devamı...
results_with_rfe = []

for category, features in selected_features.items():
    subset = data[data[category] == 1]
    X = subset[features]
    y = subset['GrainYield']

    if y.isnull().any():
        continue

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for clf_name, clf in classifiers.items():
        fold_accuracies, fold_aucs, fold_mccs, fold_f1s, fold_precisions, fold_recalls = [], [], [], [], [], []
        fold_roc_data = {'fpr': [], 'tpr': []}  # ROC verilerini toplamak için

        for train_idx, test_idx in skf.split(X_scaled, y):
            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            clf.fit(X_train, y_train)
            y_pred = clf.predict(X_test)
            y_proba = clf.predict_proba(X_test) if hasattr(clf, "predict_proba") else None

            acc = accuracy_score(y_test, y_pred)
            mcc = matthews_corrcoef(y_test, y_pred)
            f1 = f1_score(y_test, y_pred, average='weighted')
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')

            if y_proba is not None and y_proba.shape[1] == len(np.unique(y)):
                auc_score = roc_auc_score(y_test, y_proba, multi_class='ovo')
                fpr, tpr, _ = roc_curve(y_test, y_proba[:, 1], pos_label=np.unique(y)[1])  # ROC için
                fold_roc_data['fpr'].append(fpr)
                fold_roc_data['tpr'].append(tpr)
            else:
                auc_score = np.nan

            fold_accuracies.append(acc)
            fold_aucs.append(auc_score)
            fold_mccs.append(mcc)
            fold_f1s.append(f1)
            fold_precisions.append(precision)
            fold_recalls.append(recall)

        # ROC verilerini sakla (ilk fold'u kullanarak)
        if fold_roc_data['fpr']:
            roc_data[(category, clf_name)] = (fold_roc_data['fpr'][0], fold_roc_data['tpr'][0])

        results_with_rfe.append({
            'Category': category,
            'Classifier': clf_name,
            'Accuracy': np.mean(fold_accuracies),
            'AUC': np.nanmean(fold_aucs),
            'MCC': np.mean(fold_mccs),
            'F1': np.mean(fold_f1s),
            'Precision': np.mean(fold_precisions),
            'Recall': np.mean(fold_recalls),
        })

results_with_rfe_df = pd.DataFrame(results_with_rfe)
display(results_with_rfe_df)

# ROC Eğrilerini Çizme
import matplotlib.pyplot as plt
from sklearn.metrics import auc

plt.figure(figsize=(10, 8), dpi=120)
colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'lime']

# Her sınıflandırıcı için ROC eğrisi
aggregated_roc_data = {}
for (cat, clf_name), (fpr, tpr) in roc_data.items():
    if clf_name not in aggregated_roc_data:
        aggregated_roc_data[clf_name] = {'fpr': [], 'tpr': []}
    aggregated_roc_data[clf_name]['fpr'].append(fpr)
    aggregated_roc_data[clf_name]['tpr'].append(tpr)

for idx, (clf_name, values) in enumerate(aggregated_roc_data.items()):
    mean_fpr = np.linspace(0, 1, 100)
    mean_tpr = np.mean([np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(values['fpr'], values['tpr'])], axis=0)
    mean_tpr[-1] = 1.0
    roc_auc = auc(mean_fpr, mean_tpr)
    plt.plot(mean_fpr, mean_tpr, color=colors[idx % len(colors)], lw=2, label=f'{clf_name} (AUC = {roc_auc:.3f})')

# Rastgele tahmin çizgisi
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1.5, label='Random Guess')

plt.title('ROC Curves for Classifiers (Aggregated)', fontsize=14)
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.legend(loc='lower right', fontsize=10)
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

"""and now compare them with previous results ( before FS)"""

comparison_df = pd.merge(
    results_with_rfe_df,
    results_df,
    how='left',
    on=['Category', 'Classifier'],
    suffixes=('_After', '_Before')
)

comparison_df.rename(columns={
    'Accuracy_After': 'FS_After_Accuracy',
    'AUC_After': 'FS_After_AUC',
    'MCC_After': 'FS_After_MCC',
    'F1_After': 'FS_After_F1',
    'Precision_After': 'FS_After_Precision',
    'Recall_After': 'FS_After_Recall',
    'Accuracy_Before': 'FS_Before_Accuracy',
    'AUC_Before': 'FS_Before_AUC',
    'MCC_Before': 'FS_Before_MCC',
    'F1_Before': 'FS_Before_F1',
    'Precision_Before': 'FS_Before_Precision',
    'Recall_Before': 'FS_Before_Recall'
}, inplace=True)

comparison_df['Accuracy_Change'] = comparison_df['FS_After_Accuracy'] - comparison_df['FS_Before_Accuracy']
comparison_df['AUC_Change'] = comparison_df['FS_After_AUC'] - comparison_df['FS_Before_AUC']
comparison_df['MCC_Change'] = comparison_df['FS_After_MCC'] - comparison_df['FS_Before_MCC']
comparison_df['F1_Change'] = comparison_df['FS_After_F1'] - comparison_df['FS_Before_F1']
comparison_df['Precision_Change'] = comparison_df['FS_After_Precision'] - comparison_df['FS_Before_Precision']
comparison_df['Recall_Change'] = comparison_df['FS_After_Recall'] - comparison_df['FS_Before_Recall']

display(comparison_df)

print("FS sonrası kategoriler:", results_with_rfe_df['Category'].unique())
print("FS öncesi kategoriler:", results_df['Category'].unique())

"""**NAN values? hmm...**

"""

# NaN içeren satırları kontrol et
nan_rows = comparison_df[comparison_df.isna().any(axis=1)]
display(nan_rows)

"""no more nan values thanks to Veri ve kategorilerin uyumsuzluğunu giderip, hem FS öncesi hem de FS sonrası DataFrame'lerde aynı Category değerlerinin bulunduğundan emin olduk. Sonuçta merge işlemi problemsiz hale geldi. Ek olarak çıktıları düzgün şekilde display() ile gösterip SuppressOutput gibi engelleme mekanizmalarını kaldırınca her şey net şekilde görünür oldu. Bu adımları bilinçli şekilde uygulayarak sorunları çözdük."""

# accuracy difference (before and after FS)
comparison_df['Accuracy_Change'] = comparison_df['FS_After_Accuracy'] - comparison_df['FS_Before_Accuracy']

# En çok accuracy artışı elde eden ilk 10 kategori-sınıflandırıcı kombinasyonu
top_10_gain = comparison_df.sort_values('Accuracy_Change', ascending=False).head(10)

# En çok accuracy kaybeden ilk 10 kategori-sınıflandırıcı kombinasyonu
top_10_loss = comparison_df.sort_values('Accuracy_Change', ascending=True).head(10)

print("En çok accuracy kazancı (gain) olan ilk 10 Category-Classifier çifti:")
print(top_10_gain[['Category', 'Classifier', 'FS_Before_Accuracy', 'FS_After_Accuracy', 'Accuracy_Change']])

print("\nEn çok accuracy kaybı (loss) olan ilk 10 Category-Classifier çifti:")
print(top_10_loss[['Category', 'Classifier', 'FS_Before_Accuracy', 'FS_After_Accuracy', 'Accuracy_Change']])

# FS sonrası en yüksek 5 accuracy değerine sahip satırları bulalım
top_5_after_fs = comparison_df.sort_values('FS_After_Accuracy', ascending=False).head(5)

# Bu top 5 satır için Category, Classifier, FS_After_Accuracy ve seçilen özellikleri gösterelim
print("Feature Selection Sonrası En Yüksek 5 Accuracy Değeri:")
for i, row in top_5_after_fs.iterrows():
    cat = row['Category']
    clf = row['Classifier']
    acc_after = row['FS_After_Accuracy']
    # Her kategori için seçilen özellikleri selected_features sözlüğünden alıyoruz
    features = selected_features.get(cat, [])

    print(f"\nCategory: {cat}")
    print(f"Classifier: {clf}")
    print(f"FS_After_Accuracy: {acc_after:.4f}")
    print("Seçilen Özellikler:", ", ".join(features) if features else "Bu kategori için özellik bulunamadı.")

best_row = comparison_df.sort_values('FS_After_Accuracy', ascending=False).iloc[0]

# 2) Category, Classifier bilgilerini ve FS_After_Accuracy değerini alalım
best_category = best_row['Category']
best_clf_name = best_row['Classifier']
best_acc_value = best_row['FS_After_Accuracy']

print(f"En iyi FS_After_Accuracy ile bulunan satır:\nCategory: {best_category}\nClassifier: {best_clf_name}\nAccuracy: {best_acc_value:.4f}")

features = selected_features.get(best_category, [])
if not features:
    print(f"UYARI: {best_category} için 'selected_features' sözlüğünde özellik bulunamadı.")
else:
    print("\nSeçilen Özellikler (Feature Selection Sonrası):")
    for f in features:
        print("-", f)

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix

# Model seçimi
model = classifiers[best_clf_name]

# Veri alt kümesi
subset = data[data[best_category] == 1]  # Veri setinizde best_category == 1 şeklinde column varsa
X = subset[features]
y = subset['GrainYield']

# Ölçeklendirme
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Kaç sınıfınız varsa ona göre confusion matrix boyutu:
classes = np.unique(y)
n_classes = len(classes)
accum_cm = np.zeros((n_classes, n_classes), dtype=int)  # tüm fold'ların toplam CM'i tutacağız

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for train_idx, test_idx in skf.split(X_scaled, y):
    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # fold bazında confusion matrix
    cm = confusion_matrix(y_test, y_pred, labels=classes)
    accum_cm += cm  # TOPLAMA işlemi

# Toplam confusion matrix'i görselleştirme
plt.figure(figsize=(6, 5), dpi=120)
sns.heatmap(accum_cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=classes, yticklabels=classes)
plt.title(f'Confusion Matrix (Toplam 5-Fold)\nCategory: {best_category}, Classifier: {best_clf_name}')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.tight_layout()
plt.show()

print("Toplam Confusion Matrix Değerleri:\n", accum_cm)